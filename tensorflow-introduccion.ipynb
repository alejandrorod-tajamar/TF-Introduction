{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tensor Operations\n",
    "\n",
    "Basic tensor operations using TensorFlow v2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# Completa las importaciones necesarias\n",
    "import tensorflow as tf\n",
    "______ # Importar numpy como np\n",
    "______ # Importar matplotlib.pyplot como plt\n",
    "______ # Importar pandas como pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tensor constants.\n",
    "#COMPLETAR: Crear constantes a=2, b=3, c=5 usando tf.constant\n",
    "a = tf.____\n",
    "b = tf.____\n",
    "c = tf.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various tensor operations.\n",
    "# COMPLETAR: Definir operaciones add, sub, mul, div\n",
    "add = ______ # Sumar a y b\n",
    "sub = ______ # Restar a y b\n",
    "mul = ______ # Multiplicar a y b\n",
    "div = ______ # Dividir a y b\n",
    "\n",
    "# Access tensors value.\n",
    "print(\"add =\", add.numpy())\n",
    "print(\"sub =\", sub.numpy())\n",
    "print(\"mul =\", mul.numpy())\n",
    "print(\"div =\", div.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more operations.\n",
    "# COMPLETAR: Calcular media y suma de [a, b, c]\n",
    "mean = tf.____([a, b, c])\n",
    "sum = tf._____([a, b, c])\n",
    "\n",
    "# Access tensors value.\n",
    "print(\"mean =\", mean.numpy())\n",
    "print(\"sum =\", sum.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplications.\n",
    "matrix1 = tf.constant([[1., 2.], [3., 4.]])\n",
    "matrix2 = tf.constant([[5., 6.], [7., 8.]])\n",
    "\n",
    "# COMPLETAR: Multiplicar matrix1 y matrix2 (2x2)\n",
    "product = tf._____(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Tensor.\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Tensor to Numpy.\n",
    "product.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9i2Dsh-ziXr"
   },
   "source": [
    "# Fundamentos de la personalización: tensores y operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sILUVbHoSgH"
   },
   "source": [
    "Este es un tutorial de introducción a TensorFlow que muestra cómo:\n",
    "\n",
    "- Importar el paquete deseado.\n",
    "- Crear y usar tensores.\n",
    "- Usar la aceleración por GPU.\n",
    "- Construir una canalización de datos con  `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1JcS5iBXMRO"
   },
   "source": [
    "## Importar TensorFlow\n",
    "\n",
    "El primer paso es importar el módulo `tensorflow`. A partir de TensorFlow 2, eager execution está habilitado por default. Eager execution permite un front-end más interactivo para TensorFlow, que podrá ver con más detalle más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjBPmYjLdFmk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9UySOPLXdaw"
   },
   "source": [
    "## Tensores\n",
    "\n",
    "Los tensores son matrices multidimensionales. Como los objetos `ndarray` de NumPy, los objetos `tf.Tensor` tienen un tipo de datos y una forma. Además, los `tf.Tensor` pueden residir en la memoria del acelerador (como una GPU). TensorFlow provee una rica librería de operaciones (por ejemplo, `tf.math.add`, `tf.linalg.matmul`, y `tf.linalg.inv`) que consumen y producen `tf.Tensor`es. Estas operaciones convertirán automáticamente los tipos incorporados de Python. Por ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "ngUe237Wt48W"
   },
   "outputs": [],
   "source": [
    "# ========== EJEMPLOS DE TF.MATH ==========\n",
    "# Sumar dos números escalares (1 y 2)\n",
    "print(tf.math.add(1, 2))\n",
    "\n",
    "# COMPLETAR: Sumar dos listas ([1, 2] y [3, 4])\n",
    "print()\n",
    "\n",
    "# COMPLETAR: Calcular el cuadrado de 5\n",
    "print()\n",
    "\n",
    "# COMPLETAR: Calcular la suma de los elementos de [1, 2, 3]\n",
    "print()\n",
    "\n",
    "# COMPLETAR: Sumar los cuadrados de 2 y 3\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDY4WsYRhP81"
   },
   "source": [
    "Cada `tf.Tensor` tiene una forma y un tipo de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srYWH1MdJNG7"
   },
   "outputs": [],
   "source": [
    "x = tf.linalg.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBPw8e8vrsom"
   },
   "source": [
    "Las diferencias más obvias entre los `tf.Tensor` y los arreglos NumPy son:\n",
    "\n",
    "1. Los tensores pueden encontrarse en la memoria aceleradora (como GPU, TPU).\n",
    "2. Los tensores son inmutables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dwi1tdW3JBw6"
   },
   "source": [
    "### Compatibilidad con NumPy\n",
    "\n",
    "Es fácil convertir entre un `tf.Tensor` TensorFlow y un `ndarray` NumPy:\n",
    "\n",
    "- Las operaciones TensorFlow convierten automáticamente los ndarrays NumPy en Tensores.\n",
    "- Las operaciones NumPy convierten automáticamente los Tensores en ndarrays NumPy.\n",
    "\n",
    "Los tensores se convierten explícitamente en ndarrays NumPy usando su método `.numpy()`. Dado que el arreglo y el `tf.Tensor` comparten la representación de memoria subyacente cuando es posible, estas conversiones suelen ser económicas. Pero compartir la representación subyacente no siempre es posible, ya que el `tf.Tensor` puede estar en la memoria de la GPU, mientras que las matrices de NumPy siempre se encuentran en la memoria del host, y la conversión implica una copia de la GPU a la memoria del host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCUWzso6mbqR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.math.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBNP8yTRfu_X"
   },
   "source": [
    "## Aceleración por GPU\n",
    "\n",
    "Muchas operaciones de TensorFlow usan GPU para acelerar la computación. En ausencia de anotaciones, TensorFlow decide automáticamente si usar la GPU o la CPU para una operación, copiando el tensor entre la memoria de la CPU y la de la GPU si es necesario. Los tensores generados por una operación se almacenarán normalmente en la memoria del dispositivo que realizó el proceso. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "3Twf_Rw-gQFM"
   },
   "outputs": [],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpgYzgVXW2Ud"
   },
   "source": [
    "### Nombres de dispositivos\n",
    "\n",
    "La propiedad `Tensor.device` indica un nombre de cadena completamente calificado del dispositivo en el que se alojan los contenidos del Tensor. Este nombre condensa muchos detalles, como un identificador para la dirección de red del host en el que se está ejecutando este programa, y el dispositivo dentro de ese host. Un programa TensorFlow lo necesita para su ejecución distribuida. La cadena termina con `GPU:<N>` si el tensor se encuentra en la GPU número `N` del host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWZQCimzuqyP"
   },
   "source": [
    "### Colocación explícita en el dispositivo\n",
    "\n",
    "En TensorFlow, la *colocación* se refiere a cómo se asignan (colocan) las operaciones individuales a un dispositivo para su ejecución. Como se mencionó anteriormente, si no se ofrece ninguna orientación explícita, TensorFlow decidirá automáticamente en qué dispositivo debe ejecutarse una operación, y copiará los tensores a ese dispositivo si es necesario.\n",
    "\n",
    "No obstante, las operaciones TensorFlow pueden colocarse explícitamente en dispositivos específicos usando el gerente de contexto del `tf.device`. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjkNZTuauy-Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.linalg.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "\n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# Force execution on CPU\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random.uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)\n",
    "\n",
    "# Force execution on GPU #0 if available\n",
    "if tf.config.list_physical_devices(\"GPU\"):\n",
    "  print(\"On GPU:\")\n",
    "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1K4dlhhHtQj"
   },
   "source": [
    "## Conjuntos de datos\n",
    "\n",
    "Esta sección usa la API `tf.data.Dataset` para construir una canalización que suministre datos a tu modelo. `tf.data.Dataset` se usa para construir canalizaciones de entrada complejas y eficaces a partir de piezas sencillas y reutilizables que suministrarán datos a los bucles de entrenamiento o evaluación de tu modelo. (Consulte la sección [tf.data: Construir canalizaciones de entrada de TensorFlow](../../guide/data.ipynb) para saber más)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI0fmOynH-Ne"
   },
   "source": [
    "### Crear un `Dataset` fuente\n",
    "\n",
    "Cree un conjunto de datos *fuente* usando una de las funciones de fábrica como `tf.data.Dataset.from_tensors`, `tf.data.Dataset.from_tensor_slices`, o usando objetos que lean de archivos como `tf.data.TextLineDataset` o `tf.data.TFRecordDataset`. Consulte la sección *Lectura de datos de entrada* de la guía [tf.data: Construir canalizaciones de entrada de TensorFlow](../../guide/data.ipynb) para saber más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F04fVOHQIBiG"
   },
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create a CSV file\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbxIhC-5IPdf"
   },
   "source": [
    "### Aplicar transformaciones\n",
    "\n",
    "Use las funciones de transformación como `tf.data.Dataset.map`, `tf.data.Dataset.batch`, y `tf.data.Dataset.shuffle` para aplicar transformaciones a los registros del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXSDZWE-ISsd"
   },
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8X1GNfoIZKJ"
   },
   "source": [
    "### Iterar\n",
    "\n",
    "Los objetos `tf.data.Dataset` admiten la iteración para recorrer los registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws-WKRk5Ic6-"
   },
   "outputs": [],
   "source": [
    "print('Elements of ds_tensors:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nElements in ds_file:')\n",
    "for x in ds_file:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# TensorFlow 2: Iniciación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "En esta breve introducción se usa [Keras](https://www.tensorflow.org/guide/keras/overview) para:\n",
    "\n",
    "1. Cargar un conjunto de datos predeterminado.\n",
    "2. Crear un modelo de aprendizaje automático de red neural que clasifique las imágenes.\n",
    "3. Entrenar la red neural.\n",
    "4. Evaluar la exactitud del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## Preparación de TensorFlow\n",
    "\n",
    "Para empezar, importe TensorFlow a su programa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "\n",
    "Nota: controle haber actualizado a la última versión de `pip` para instalar el paquete de TensorFlow 2 en caso de que use su propio entorno de desarrollo. Para más detalles, consulte la [guía de instalación](https://www.tensorflow.org/install).\n",
    "\n",
    "## Carga de un conjunto de datos\n",
    "\n",
    "Cargue y prepare [conjunto de datos MNIST](http://yann.lecun.com/exdb/mnist/). Los valores de los pixeles de las imágenes van de 0 a 255. Escale esos valores a un rango de 0 a 1 dividiendo los valores por `255.0`. De este modo, también se convierten los datos de muestra de los enteros a números de punto flotante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Cargar MNIST y normalizar\n",
    "(______, ______), (______, ______) = mnist.load_data()\n",
    "x_train, x_test = ______ / 255.0, ______ / 255.0  # Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "## Creación de un modelo de aprendizaje automático\n",
    "\n",
    "Cree un modelo `tf.keras.Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2hiez2eIUz8"
   },
   "source": [
    "[`Sequential`](https://www.tensorflow.org/guide/keras/sequential_model) es útil para apilar capas donde cada una tiene un [tensor](https://www.tensorflow.org/guide/tensor) de entrada y uno de salida. Las capas son funciones con una estructura matemática desconocida que se puede reutilizar y que tiene variables entrenables. La mayoría de los modelos TensorFlow están compuestos por capas. Este modelo usa las capas [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) y [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout).\n",
    "\n",
    "Para cada ejemplo, el modelo devuelve un vector de [logits](https://developers.google.com/machine-learning/glossary#logits) o puntajes de [log-odds](https://developers.google.com/machine-learning/glossary#log-odds) (registro de probabilidades) por cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeOrNdnkEEcR"
   },
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgjhDQGcIniO"
   },
   "source": [
    "La función `tf.nn.softmax` convierte estas funciones logits en *probabilidades* para cada clase: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWSRnQ0WI5eq"
   },
   "outputs": [],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he5u_okAYS4a"
   },
   "source": [
    "Nota: es posible aplicar la función `tf.nn.softmax` en la función de activación para la última capa de la red. Si bien esto puede hacer que la salida del modelo se interprete más directamente, este enfoque no se recomienda ya que es imposible proporcionar un cálculo de pérdida numéricamente estable y exacto para todos los modelos con salida softmax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQyugpgRIyrA"
   },
   "source": [
    "Defina la función de pérdida para el entrenamiento con `losses.SparseCategoricalCrossentropy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSkzdv8MD0tT"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfR4MsSDU880"
   },
   "source": [
    "La función de pérdida toma un vector de valores verdaderos de base y un vector de logits y devuelve una pérdida escalar para cada ejemplo. Esta pérdida es igual a la probabilidad de registro negativa de la clase verdadera: La pérdida es cero si el modelo está seguro de la clase correcta.\n",
    "\n",
    "El modelo sin entrenar arroja probabilidades cercanas al lo aleatorio (1/10 para cada clase), entonces, la pérdida inicial debería estar cerca de `-tf.math.log(1/10) ~= 2.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJWqEVrrJ7ZB"
   },
   "outputs": [],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ada44eb947d4"
   },
   "source": [
    "Antes de empezar el entrenamiento, configure y compile el modelo con Keras `Model.compile`. Configure la clase del [`optimizador`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) como `adam`, establezca `loss` para la función `loss_fn` que definió antes y especifique una métrica a evaluar para el modelo, mediante la determinación del parámetro `metrics` para `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9foNKHzTD2Vo"
   },
   "outputs": [],
   "source": [
    "# === COMPILACIÓN DEL MODELO ===\n",
    "# Compila con:\n",
    "# - Optimizer: Adam\n",
    "# - Métrica: accuracy\n",
    "model.______(\n",
    "    optimizer=______,\n",
    "    loss=loss_fn,\n",
    "    metrics=______\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "## Entrenamiento y evaluación del modelo\n",
    "\n",
    "Use el método `Model.fit` para ajustar los parámetros del modelo y minimizar la pérdida: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7suUbJXVLqP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === ENTRENAMIENTO ===\n",
    "# Entrena por 5 épocas\n",
    "model.______(\n",
    "    ______,\n",
    "    ______,\n",
    "    epochs=______\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mDAAPFqVVgn"
   },
   "source": [
    "El método `Model.evaluate` controla el desempeño del modelo, por lo general con un [conjunto de evaluación](https://developers.google.com/machine-learning/glossary#validation-set) o un [conjunto de prueba](https://developers.google.com/machine-learning/glossary#test-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7dTAzgHDUh7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === EVALUACIÓN ===\n",
    "# Evalúa el modelo con los datos de test\n",
    "model.evaluate( ____ , y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "El clasificador de imágenes ahora está entrenado para proporcionar ~98% de exactitud en este conjunto de datos. Para más información, lea los [tutoriales de TensorFlow](https://www.tensorflow.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj8NrlzlJqDG"
   },
   "source": [
    "Si desea que su modelo devuelva una probabilidad, puede empaquetar el modelo entrenado y adjuntarle el softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYb6DrEH0GMv"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnqOZtUp1YR_"
   },
   "outputs": [],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Clasificación básica: clasifique imágenes de prendas de vestir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "Esta guía sirve para entrenar un modelo de redes neuronales para que clasifique imágenes de prendas de vestir, como calzado y camisas. No es necesario que entienda todos los detalles; este es un resumen rápido de un programa completo de TensorFlow donde se explican todos los detalles sobre la marcha.\n",
    "\n",
    "Esta guía usa [tf.keras](https://www.tensorflow.org/guide/keras), una API de alto nivel que se usa para desarrollar y entrenar modelos en TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Importar el conjunto de datos Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "Esta guía usa el conjunto de datos [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) que contiene 70 000 imágenes en escala de grises en 10 categorías. Las imágenes muestran artículos individuales de prendas de vestir en baja resolución (28 x 28 píxeles), como se puede ver a continuación:\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\" alt=\"Fashion MNIST sprite\" width=\"600\">   </td></tr>\n",
    "  <tr><td align=\"center\">     <b>Figura 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Muestras de Fashion-MNIST</a> (de Zalando, licencia MIT).<br> </td></tr>\n",
    "</table>\n",
    "\n",
    "Fashion MNIST fue pensado como reemplazo directo del clásico conjunto de datos [MNIST](http://yann.lecun.com/exdb/mnist/), a menudo usado como el \"Hola, mundo\" de los programas de aprendizaje automático para visión artificial. El conjunto de datos MNIST contiene imágenes de dígitos escritos a mano (0, 1, 2, etc.) en un formato idéntico al de las prendas de vestir que usará aquí.\n",
    "\n",
    "Esta guía usa Fashion MNIST para variar y porque constituye un desafío ligeramente más difícil que el MNIST común. Ambos conjuntos de datos son relativamente pequeños y se usan para comprobar que un algoritmo funcione según lo previsto. Suponen un buen punto de partida para la prueba y depuración de los códigos.\n",
    "\n",
    "Aquí, se utilizan 60 000 imágenes para entrenar la red y 10 000 imágenes para evaluar la precisión con la que la red aprendió a clasificar imágenes. Puede acceder a Fashion MNIST directamente desde TensorFlow. Importe y [cargue los datos de Fashion MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) directamente desde TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "Cargar el conjunto de datos devuelve cuatro arreglos NumPy:\n",
    "\n",
    "- Los arreglos `train_images` y `train_labels` constituyen el *conjunto de entrenamiento*, los datos que el modelo usa para aprender.\n",
    "- El modelo se compara con el *conjunto de prueba*, los arreglos `test_images`, y `test_labels`.\n",
    "\n",
    "Las imágenes son arreglos NumPy de 28x28, con valores de píxeles que van de 0 a 255. Las *letiquetas* son un arreglo de números enteros, que van de 0 a 9. Estos corresponden a la *clase* de prenda de vestir que representa la imagen:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Etiqueta</th>\n",
    "    <th>Clase</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Cada imagen se asigna a una etiqueta única. Dado que los *nombres de las clases* no se incluyen en los conjuntos de datos, almacénelos aquí para usarlos más tarde, al trazar las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Explorar los datos\n",
    "\n",
    "Antes de entrenar el modelo, exploremos el formato del conjunto de datos. A continuación, se muestra que el conjunto de entrenamiento contiene 60 000 imágenes, cada una de las cuales se representa por 28 x 28 píxeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIAcvQqMCaWf"
   },
   "source": [
    "Asimismo, el conjunto de entrenamiento consta de 60 000 etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSlYxFuRCaWk"
   },
   "source": [
    "Cada etiqueta es un número entero entre 0 y 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "El conjunto de prueba está compuesto por 10 000 imágenes. Del mismo modo, cada imagen está representada por 28 x 28 píxeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0A0Iu0CaWq"
   },
   "source": [
    "Y el conjunto de prueba contiene 10 000 etiquetas de imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Los datos se deben preprocesar antes de entrenar la red. Si inspecciona la primera imagen en el conjunto de entrenamiento, verá que los valores de los píxeles se encuentran entre 0 y 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "Escale estos valores a un rango de 0 a 1 antes de cargarlos al modelo de red neuronal. Para ello, divida los valores por 255. Es importante que el *conjunto de entrenamiento* y el *conjunto de prueba* se preprocesen del mismo modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "Para verificar que los datos tengan el formato correcto y que usted esté listo para generar y entrenar la red, mostraremos las primeras 25 imágenes del *conjunto de entrenamiento* con el nombre de la clase debajo de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Generar el modelo\n",
    "\n",
    "Para generar la red neuronal es necesario configurar las capas del modelo y, a continuación, compilar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### Configurar las capas\n",
    "\n",
    "La [*capa*](https://www.tensorflow.org/api_docs/python/tf/keras/layers) es el componente básico de una red neuronal. Las capas extraen las representaciones de los datos que les cargan. Se espera que dichas representaciones sean significativas para el problema en cuestión.\n",
    "\n",
    "La mayor parte del aprendizaje profundo consiste en encadenar capas simples. La mayoría de las capas, como `tf.keras.layers.Dense`, tienen parámetros que se aprenden durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "# Crea modelo secuencial con:\n",
    "# 1. Capa Flatten de entrada (28,28)\n",
    "# 2. Capa Dense de 128 neuronas con activación ReLU\n",
    "# 4. Capa Dense de salida con 10 neuronas\n",
    "model = tf.keras.Sequential([\n",
    "    ______,\n",
    "    ______,\n",
    "    ______,\n",
    "    ______\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "La primera capa de esta red, `tf.keras.layers.Flatten`, transforma el formato de las imágenes de un arreglo de dos dimensiones (de 28 x 28 píxeles) a un arreglo de una dimensión (de 28 * 28 = 784 píxeles). Piense en esta capa como una forma de desapilar las filas de píxeles de la imagen y alinearlas. Esta capa no tiene parámetros que aprender; sólo vuelve a dar formato a los datos.\n",
    "\n",
    "Luego de aplanar los píxeles, la red consiste de una secuencia de dos capas `tf.keras.layers.Dense`. Estas son capas neuronales densamente conectadas (o completamente conectadas). La primera capa `Dense` cuenta de 128 nodos (o neuronas). La segunda (y última capa) devuelve un arreglo logits con una longitud de 10. Cada nodo contiene un puntaje que indica que la imagen actual pertenece a una de las 10 clases.\n",
    "\n",
    "### Compilar el modelo\n",
    "\n",
    "Antes de que el modelo esté listo para entrenamiento, necesita algunos ajustes más. Estos ajustes se agregan durante el paso de [*compilación*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) del modelo:\n",
    "\n",
    "- [*Función de pérdida*](https://www.tensorflow.org/api_docs/python/tf/keras/losses): mide el nivel de precisión del modelo durante el entrenamiento. Se busca minimizar esta función para \"dirigir\" el modelo en la dirección correcta.\n",
    "- [*Optimizador*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers): se refiere al modo en que se actualiza el modelo en función de los datos que ve y su función de pérdida.\n",
    "- [*Métricas*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics): se usan para monitorear los pasos de entrenamiento y prueba. El siguiente ejemplo usa *precisión*, la fracción de imágenes que se clasificaron correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# Compila con:\n",
    "# - Optimizer: Adam\n",
    "# - Métrica: accuracy\n",
    "model.______(\n",
    "    optimizer=______,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=______\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "Para entrenar el modelo de redes neuronales, se requieren los siguientes pasos:\n",
    "\n",
    "1. Cargue los datos de entrenamiento al modelo. En este ejemplo, los datos de entrenamiento están en los arreglos `train_images` y `train_labels`.\n",
    "2. El modelo aprende a asociar imágenes con etiquetas.\n",
    "3. Usted le pide al modelo que haga predicciones sobre un conjunto de prueba, en este ejemplo, el arreglo `test_images`.\n",
    "4. Verifique que las predicciones coincidan con las etiquetas del arreglo `test_labels`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "### Cargar el modelo\n",
    "\n",
    "Para comenzar el entrenamiento, llame el método [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), llamado así porque \"ajusta\" el modelo a los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === ENTRENAMIENTO ===\n",
    "# Entrena por 10 épocas\n",
    "model.______(\n",
    "    ______,\n",
    "    ______,\n",
    "    epochs=______\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "A medida que se entrena el modelo, se muestran las métricas de pérdida y precisión. Este modelo alcanza una precisión de 0,91 (o 91 %) en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "### Evaluar la precisión\n",
    "\n",
    "A continuación, compare el rendimiento del modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === EVALUACIÓN ===\n",
    "# Evalúa el modelo con los datos de test\n",
    "test_loss , test_acc =  model.evaluate( ____ , ____ , verbose=2)\n",
    "\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "Se observa que la precisión del conjunto de prueba es un poco menor que la precisión del conjunto de entrenamiento. Esta brecha entre la precisión de entrenamiento y de prueba representa un *sobreajuste*. El sobreajuste se produce cuando un modelo de aprendizaje automático rinde menos con entradas nuevas o desconocidas que con los datos de entrenamiento. Un modelo sobreajustado \"memoriza\" el ruido y los detalles del conjunto de datos de entrenamiento en una medida que afecta negativamente el rendimiento del modelo con los nuevos datos. Si desea obtener más información, consulte los siguientes recursos:\n",
    "\n",
    "- [Demostrar sobreajuste](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
    "- [Estrategias para evitar el sobreajuste](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### Hacer predicciones\n",
    "\n",
    "Una vez que cuenta con el modelo entrenado, puede usarlo para hacer predicciones sobre algunas imágenes. Adjunte una capa softmax para convertir las salidas lineales del modelo ([logits](https://developers.google.com/machine-learning/glossary#logits)) en probabilidades, que deberían ser más fáciles de interpretar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "# === PREDICCIÓN ===\n",
    "# Realiza una predicción con el modelo \n",
    "predictions = _____._____(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "Aquí, el modelo predijo la etiqueta para cada imagen del conjunto de prueba. Veamos la primera predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "Una predicción es un arreglo de 10 números que representan la \"confianza\" del modelo en que la imagen corresponde a una de las 10 distintas prendas de vestir. Puede ver qué etiqueta tiene el valor de confianza más alto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "Entonces, el modelo tiene más confianza en que esta imagen corresponde a una botineta, o `class_names[9]`. Al examinar la etiqueta de prueba vemos que esta clasificación es correcta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "Grafique esto para ver el conjunto completo de predicciones de 10 clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### Verificar las predicciones\n",
    "\n",
    "Cuando haya entrenado el modelo, podrá usarlo para hacer predicciones de algunas imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "Veamos la imagen 0, las predicciones y el arreglo de predicción. Las predicciones correctas se muestran en azul y las etiquetas de las predicciones incorrectas en rojo. El número indica el porcentaje (de 100) de la etiqueta predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Tracemos varias imágenes con sus predicciones. Tenga en cuenta que el modelo puede equivocarse incluso cuando el nivel de confianza sea alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## Usar el modelo entrenado\n",
    "\n",
    "Por último, use el modelo entrenado para hacer predicciones de una sola imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "# Grab an image from the test dataset.\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "Los modelos `tf.keras` se optimizaron para hacer predicciones sobre un *lote*, o colección, de ejemplos al mismo tiempo. Por lo tanto, aunque utilice una sola imagen, debe añadirla a una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "Ahora, prediga la etiqueta correcta para esta imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "# === PREDICCIÓN ===\n",
    "# Realiza una predicción con el modelo \n",
    "predictions_single = _____._____(img)\n",
    "\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`tf.keras.Model.predict` devuelve una lista de listas (una lista para cada imagen del lote de datos). Tome las predicciones de nuestra (única) imagen en el lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "Y el modelo predice una etiqueta, como era de esperarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Cargar datos CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "Este tutorial da ejemplos de cómo usar datos CSV con TensorFlow.\n",
    "\n",
    "Hay dos partes principales:\n",
    "\n",
    "1. **Cargar los datos del disco**\n",
    "2. **Preprocesarlos en una forma adecuada para el entrenamiento.**\n",
    "\n",
    "Este tutorial se centra en la carga y ofrece algunos ejemplos rápidos de preprocesamiento. Para aprender más sobre el aspecto del preprocesamiento, consulte la guía [Trabajar con capas de preprocesamiento](https://www.tensorflow.org/guide/keras/preprocessing_layers) y el tutorial [Clasificar datos estructurados utilizando capas de preprocesamiento Keras](../structured_data/preprocessing_layers.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZhJYbJxHNGJ"
   },
   "source": [
    "## Cargar datos en la memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ny5TEgcmHjVx"
   },
   "source": [
    "Para cualquier conjunto de datos CSV pequeño, la forma más sencilla de entrenar un modelo TensorFlow en él es cargarlo en memoria como un Dataframe pandas o un arreglo de NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgpBOuU8PGFf"
   },
   "source": [
    "Un ejemplo relativamente sencillo es el [conjunto de datos de abalones](https://archive.ics.uci.edu/ml/datasets/abalone).\n",
    "\n",
    "- El conjunto de datos es pequeño.\n",
    "- Todas las características de entrada son valores de punto flotante de rango limitado.\n",
    "\n",
    "Así es como se descargan los datos en un [`DataFrame` pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZVExo9DKoNz"
   },
   "outputs": [],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP22mdyPQ1_t"
   },
   "source": [
    "El conjunto de datos contiene una serie de mediciones de [abalones](https://en.wikipedia.org/wiki/Abalone), un tipo de molusco marino.\n",
    "\n",
    "![una concha de abalón](https://tensorflow.org/images/abalone_shell.jpg)\n",
    "\n",
    "[“Concha de abalón”](https://www.flickr.com/photos/thenickster/16641048623/) (por [Nicki Dugan Pogue](https://www.flickr.com/photos/thenickster/), CC BY-SA 2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlfGrk_9N-wf"
   },
   "source": [
    "La tarea nominal de este conjunto de datos es predecir la edad a partir de las demás medidas, por lo que se separan las características y las etiquetas para el entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udOnDJOxNi7p"
   },
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seK9n71-UBfT"
   },
   "source": [
    "Para este conjunto de datos tratará todas las características de forma idéntica. Empaquete las características en un único arreglo NumPy.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dp3N5McbUMwb"
   },
   "outputs": [],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C1yFOxLOdxh"
   },
   "source": [
    "Luego haga que un modelo de regresión prediga la edad. Dado que sólo hay un único tensor de entrada, basta aquí con un modelo `tf.keras.Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8zzNrZqOmfB"
   },
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6IWeP78O2wE"
   },
   "source": [
    "Para entrenar ese modelo, pase las características y las etiquetas a `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZdpCD92SN3Z"
   },
   "outputs": [],
   "source": [
    "# === ENTRENAMIENTO ===\n",
    "# Entrena por 10 épocas\n",
    "abalone_model.______(\n",
    "    abalone_features,\n",
    "    ______,\n",
    "    epochs=______\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GapLOj1OOTQH"
   },
   "source": [
    "Acaba de ver la forma más básica de entrenar un modelo usando datos CSV. Ahora, aprenderá a aplicar el preprocesamiento para normalizar las columnas numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B87Rd1SOUv02"
   },
   "source": [
    "## Preprocesamiento básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCrB2Jd-U0Vt"
   },
   "source": [
    "Es una buena práctica normalizar las entradas a su modelo. Las capas de preprocesamiento Keras aportan una forma cómoda de incorporar esta normalización a su modelo.\n",
    "\n",
    "La capa `tf.keras.layers.Normalization` calcula previamente la media y la varianza de cada columna, y las usa para normalizar los datos.\n",
    "\n",
    "En primer lugar, cree la capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2WQpDU5VRk7"
   },
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGgEZE-7Vpt6"
   },
   "source": [
    "Luego, use el método `Normalization.adapt` para adaptar la capa de normalización a sus datos.\n",
    "\n",
    "Nota: Utilice únicamente sus datos de entrenamiento con el método `PreprocessingLayer.adapt`. No use sus datos de validación o de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WgOPIiOVpLg"
   },
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE6vh0byV7cE"
   },
   "source": [
    "Luego, use la capa de normalización en su modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quPcZ9dTWA9A"
   },
   "outputs": [],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "# === ENTRENAMIENTO ===\n",
    "# Entrena por 10 épocas\n",
    "abalone_model.______(\n",
    "    abalone_features,\n",
    "    ______,\n",
    "    epochs=______\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Tipos de datos mezclados\n",
    "\n",
    "El conjunto de datos \"Titanic\" contiene información sobre los pasajeros del Titanic. La tarea nominal en este conjunto de datos es predecir quién sobrevivió.\n",
    "\n",
    "![El Titanic](images/csv/Titanic.jpg)\n",
    "\n",
    "Imagen de [Wikimedia](https://commons.wikimedia.org/wiki/File:RMS_Titanic_3.jpg)\n",
    "\n",
    "Los datos sin procesar pueden cargarse fácilmente como un `DataFrame` de Pandas, pero no son inmediatamente utilizables como entrada para un modelo TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS-dBMpuYMnz"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8rCGIK1ZzKx"
   },
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urHOwpCDYtcI"
   },
   "source": [
    "Como los tipos de datos y rangos son diferentes, no puede simplemente acumular las funciones en un arreglo NumPy y pasarlo a un modelo `tf.keras.Sequential`. Cada columna necesita ser manejada individualmente.\n",
    "\n",
    "Como opción, podría preprocesar sus datos fuera de línea (usando cualquier herramienta que desee) para convertir columnas categóricas en columnas numéricas, y luego pasar la salida procesada a su modelo TensorFlow. La desventaja de ese enfoque es que si guarda y exporta su modelo, el preprocesamiento no se guarda con él. Las capas Keras de preprocesamiento evitan este problema porque forman parte del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bta4Sx0Zau5v"
   },
   "source": [
    "En este ejemplo, construirá un modelo que implementa la lógica de preprocesamiento usando [la API funcional de Keras](https://www.tensorflow.org/guide/keras/functional). También podría hacerlo mediante [subclases](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n",
    "\n",
    "La API funcional opera con tensores \"simbólicos\". Los tensores \"eager\" normales tienen un valor. En cambio, estos tensores \"simbólicos\" no lo tienen. En su lugar, llevan un seguimiento de las operaciones que se ejecutan sobre ellos, y construyen una representación del cálculo, que puede ejecutar más tarde. He aquí un ejemplo rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "730F16_97D-3"
   },
   "outputs": [],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Perform a calculation using the input\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtcNXWB18kMJ"
   },
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNS9lT7f6_U2"
   },
   "source": [
    "Para construir el modelo de preprocesamiento, se empieza por construir un conjunto de objetos simbólicos `tf.keras.Input`, que coincidan con los nombres y tipos de datos de las columnas CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WODe_1da3yw"
   },
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaheJFmymq8l"
   },
   "source": [
    "El primer paso en su lógica de preprocesamiento es concatenar las entradas numéricas y hacerlas pasar por una capa de normalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPRC_E6rkp8D"
   },
   "outputs": [],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JoR45Uj712l"
   },
   "source": [
    "Recoge todos los resultados del preprocesamiento simbólico, para concatenarlos posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7jIJw5XntdN"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0Hryylyosfm"
   },
   "source": [
    "Para las entradas de cadena use la función `tf.keras.layers.StringLookup` para mapear de cadenas a índices enteros en un vocabulario. A continuación, use `tf.keras.layers.CategoryEncoding` para convertir los índices en datos `float32` apropiados para el modelo.\n",
    "\n",
    "Los ajustes predeterminados para la capa `tf.keras.layers.CategoryEncoding` crean un vector de un solo golpe para cada entrada. Una capa `tf.keras.layers.Embedding` también funcionaría. Consulte la guía [Trabajar con capas de preprocesamiento](https://www.tensorflow.org/guide/keras/preprocessing_layers) y el tutorial [Clasificar datos estructurados usando capas de preprocesamiento Keras](../structured_data/preprocessing_layers.ipynb) para más información sobre este tema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79fi1Cgan2YV"
   },
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  \n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnhv0T7itnc7"
   },
   "source": [
    "Con la recolección de `inputs` y `preprocessed_inputs`, puede concatenar todas las entradas preprocesadas y construir un modelo que se encargue del preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJRzUTe8ukXc"
   },
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNHxrNW8vdda"
   },
   "source": [
    "Este modelo sólo contiene el preprocesamiento de entrada. Puede ejecutarlo para ver lo que hace con sus datos. Los modelos Keras no convierten automáticamente los pandas `DataFrame`s porque no está claro si se debe convertir a un tensor o a un diccionario de tensores. Por lo tanto, conviértalo en un diccionario de tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YjdYyMEacwQ"
   },
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nKJYoPByada"
   },
   "source": [
    "Corte el primer ejemplo de entrenamiento y páselo a este modelo de preprocesamiento, verá las características numéricas y las cadenas de un solo paso todas concatenadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjnmU8PSv8T3"
   },
   "outputs": [],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkBf4LvmzMDp"
   },
   "source": [
    "Ahora, construya el modelo sobre esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIPtGaCzUV7"
   },
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK5uBQQF2KbZ"
   },
   "source": [
    "Cuando entrene el modelo, pase el diccionario de características como `x`, y la etiqueta como `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1gVfwJ61ejz"
   },
   "outputs": [],
   "source": [
    "# === ENTRENAMIENTO ===\n",
    "# Entrena por 10 épocas\n",
    "titanic_model.______(\n",
    "    titanic_features_dict,\n",
    "    ______,\n",
    "    epochs=______\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgJarZk3bfH"
   },
   "source": [
    "Dado que el preprocesamiento forma parte del modelo, puede guardar el modelo y volver a cargarlo en otro lugar y obtener resultados idénticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay-8ymNA2ZCh"
   },
   "outputs": [],
   "source": [
    "# === GUARDAR/CARGAR MODELO ===\n",
    "# Guarda el modelo completo en formato Keras\n",
    "______.save('test.keras')\n",
    "\n",
    "# Carga el modelo guardado\n",
    "reloaded = tf.keras.models._____(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qm6jMTpD20lK"
   },
   "outputs": [],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VsPlxIRZpXf"
   },
   "source": [
    "## Usar tf.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyVDCwGzR5HW"
   },
   "source": [
    "En la sección anterior, usted confió en el mezclado y procesamiento por lotes de datos incorporado en el modelo durante el entrenamiento del mismo.\n",
    "\n",
    "Si necesita más control sobre la canalización de los datos de entrada o necesita usar datos que no caben fácilmente en la memoria: use `tf.data`.\n",
    "\n",
    "Para más ejemplos, consulte la [`tf.data`: Construir canalizaciones de entrada TensorFlow](../../guide/data.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP5Y1jM2Sor0"
   },
   "source": [
    "### Sobre datos en memoria\n",
    "\n",
    "Como primer ejemplo de aplicación de `tf.data` a datos CSV, considere el siguiente código para trocear manualmente el diccionario de características de la sección anterior. Para cada índice, toma ese índice para cada característica:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8wE-MVuVu7_"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ3RTbS9YEal"
   },
   "source": [
    "Ejecútelo e imprima el primer ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwq8XK88WwFk"
   },
   "outputs": [],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvp8Dct6YOIE"
   },
   "source": [
    "El cargador de datos en memoria `tf.data.Dataset` más básico es el constructor `Dataset.from_tensor_slices`. Éste devuelve un `tf.data.Dataset` que implementa una versión generalizada de la función `slices` anterior, en TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gEJthslYxeV"
   },
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZC0rTpMZMZK"
   },
   "source": [
    "Puede iterar sobre un `tf.data.Dataset` como cualquier otro iterable de python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOHbiefaY4ag"
   },
   "outputs": [],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwcFoVJWZY5F"
   },
   "source": [
    "La función `from_tensor_slices` puede manejar cualquier estructura de diccionarios anidados o tuplas. El siguiente código crea un conjunto de datos de pares `(features_dict, labels)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIHGBy76Zcrx"
   },
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQwxitt8c2GK"
   },
   "source": [
    "Para entrenar un modelo usando este `Dataset`, necesitará al menos hacer `shuffle` y `batch` los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbJcbldhddeC"
   },
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4FRqhRFuoJx"
   },
   "source": [
    "En lugar de pasar `features` y `labels` a `Model.fit`, se pasa el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yXkNPumdBtB"
   },
   "outputs": [],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXuibiv9exT7"
   },
   "source": [
    "### Desde un único archivo\n",
    "\n",
    "Hasta ahora este tutorial ha trabajado con datos en memoria. `tf.data` es un conjunto de herramientas altamente escalable para construir canalizaciones de datos, y ofrece algunas funciones para tratar la carga de archivos CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Ahora lea los datos CSV del archivo y cree un `tf.data.Dataset`.\n",
    "\n",
    "(Para ver la documentación completa, consulte `tf.data.experimental.make_csv_dataset`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIbUscB9sqha"
   },
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf3v3BKgy4AG"
   },
   "source": [
    "Esta función incluye muchas características convenientes, por lo que es fácil trabajar con los datos. Esto incluye:\n",
    "\n",
    "- Usar las cabeceras de las columnas como claves del diccionario.\n",
    "- Determinar automáticamente el tipo de cada columna.\n",
    "\n",
    "Precaución: Asegúrese de establecer el argumento `num_epochs` en `tf.data.experimental.make_csv_dataset`, de lo contrario el comportamiento predeterminado para `tf.data.Dataset` es hacer un bucle sin fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4oMO9MIxgTG"
   },
   "outputs": [],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-TgA6o2Ja6U"
   },
   "source": [
    "Nota: Si ejecuta la celda anterior dos veces producirá resultados diferentes. Los ajustes predeterminados para `tf.data.experimental.make_csv_dataset` incluyen `shuffle_buffer_size=1000`, que es más que suficiente para este pequeño conjunto de datos, pero puede no serlo para un conjunto de datos del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6uviU_KCCWD"
   },
   "source": [
    "También puede descomprimir los datos sobre la marcha. Aquí tiene un archivo CSV descomprimido que contiene el [conjunto de datos de tráfico interestatal de metro](https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume).\n",
    "\n",
    "![Un atasco de tráfico.](images/csv/traffic.jpg)\n",
    "\n",
    "Imagen [de Wikimedia](https://commons.wikimedia.org/wiki/File:Trafficjam.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kT7oZI2E46Q8"
   },
   "outputs": [],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-IOsFHbCw0i"
   },
   "source": [
    "Ajuste el argumento `compression_type` para leer directamente del archivo comprimido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ar0MPEVJ5NeA"
   },
   "outputs": [],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p12Y6tGq8D6M"
   },
   "source": [
    "Nota: Si necesita analizar esas cadenas de fecha y hora en la canalización `tfa.data`, puede usar `tfa.text.parse_time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtrAXzYGP3l0"
   },
   "source": [
    "### Almacenamiento en caché"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN2dL_LRP83r"
   },
   "source": [
    "El análisis sintáctico de los datos CSV conlleva algunos esfuerzos. Para los modelos pequeños esto puede ser el cuello de botella en el entrenamiento.\n",
    "\n",
    "Dependiendo de su caso de uso, puede ser una buena idea usar `Dataset.cache` o `tf.data.Dataset.snapshot`, para que los datos CSV sólo se parseen en la primera época.\n",
    "\n",
    "La principal diferencia entre los métodos `cache` y `snapshot` es que los archivos `cache` sólo pueden ser usados por el proceso TensorFlow que los creó, pero los archivos `snapshot` pueden ser leídos por otros procesos.\n",
    "\n",
    "Por ejemplo, iterar sobre el `traffic_volume_csv_gz_ds` 20 veces puede llevar unos 15 segundos sin almacenamiento en caché, o unos dos segundos con almacenamiento en caché."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qk38Sw4MO4eh"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN3HtDONh5TX"
   },
   "source": [
    "Nota: `Dataset.cache` almacena los datos de la primera época y los reproduce en orden. Por tanto, usar el método `cache` desactiva cualquier mezcla anterior en la canalización. Más adelante, `Dataset.shuffle` se vuelve a añadir después de `Dataset.cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5Jj72MrPbnh"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN7uUBjmgNZ9"
   },
   "source": [
    "Nota: Los archivos `tf.data.Dataset.snapshot` están pensados para el almacenamiento *temporal* de un conjunto de datos mientras se usa. Este *no* es un formato para el almacenamiento a largo plazo. El formato de archivo se considera un detalle interno, y no se garantiza entre las versiones de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHGD1E8ktUvW"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "snapshotting = traffic_volume_csv_gz_ds.snapshot('titanic.tfsnap').shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUSSegnMCGRz"
   },
   "source": [
    "Si la carga de sus datos se ralentiza al cargar archivos CSV, y `Dataset.cache` y `tf.data.Dataset.snapshot` son insuficientes para su caso de uso, considere la posibilidad de recodificar sus datos en un formato más ágil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtEZ1pCPn--z"
   },
   "source": [
    "# Entrenamiento personalizado: tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDrzLFXE8T1l"
   },
   "source": [
    "Este tutorial le muestra cómo entrenar un modelo de aprendizaje automático con un bucle de entrenamiento personalizado para *categorizar* pingüinos por especies. En este bloc de notas, usará TensorFlow para hacer lo siguiente:\n",
    "\n",
    "1. Importar un conjunto de datos\n",
    "2. Construir un modelo lineal simple\n",
    "3. Entrenar el modelo\n",
    "4. Evaluar la eficacia del modelo\n",
    "5. Usar el modelo entrenado para hacer predicciones\n",
    "\n",
    "## Programar el TensorFlow\n",
    "\n",
    "Este tutorial demuestra las siguientes tareas de programación de TensorFlow:\n",
    "\n",
    "- Importar datos con la [API de conjuntos de datos de TensorFlow](https://www.tensorflow.org/datasets/overview#load_a_dataset)\n",
    "- Construir modelos y capas con la [API Keras](https://www.tensorflow.org/guide/keras/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx7wc0LuuxaJ"
   },
   "source": [
    "## Problema de clasificación de pingüinos\n",
    "\n",
    "Imagine que es un ornitólogo en busca de cómo categorizar automáticamente cada pingüino que encuentra. El aprendizaje automático ofrece muchos algoritmos para clasificar pingüinos estadísticamente. Por ejemplo, un sofisticado programa de aprendizaje automático podría clasificar pingüinos basándose en fotografías. El modelo que construye en este tutorial es un poco más sencillo. Clasifica a los pingüinos basándose en su peso corporal, la longitud de sus aletas y sus picos, es decir, la longitud y anchura de su [culmen](https://en.wikipedia.org/wiki/Beak#Culmen).\n",
    "\n",
    "Hay 18 especies de pingüinos, pero en este tutorial sólo intentará clasificar las tres siguientes:\n",
    "\n",
    "- Pingüinos barbijo\n",
    "- Pingüinos gentú\n",
    "- Pingüinos de Adelia\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://www.tensorflow.org/tutorials/customization/images/penguins_ds_species.png\" class=\"no-filter\" alt=\"Ilustración de los pingüinos barbijo, gentú y de Adelia\"> </td></tr>\n",
    "  <tr><td align=\"center\">     <b>Figura 1.</b> Pingüinos <a href=\"https://en.wikipedia.org/wiki/Chinstrap_penguin\">barbijo</a>, <a href=\"https://en.wikipedia.org/wiki/Gentoo_penguin\">gentú</a>, y <a href=\"https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin\">de Adelia</a> (Ilustraciones de @allison_horst, CC BY-SA 2.0).<br> </td></tr>\n",
    "</table>\n",
    "\n",
    "Por suerte, un equipo de investigadores ya ha creado y compartido un [conjunto de datos de 334 pingüinos](https://allisonhorst.github.io/palmerpenguins/) con peso corporal, longitud de las aletas, medidas del pico y otros datos. Este conjunto de datos también está convenientemente disponible como el Conjunto de Datos TensorFlow [penguins](https://www.tensorflow.org/datasets/catalog/penguins). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1J3AuPBT9gyR"
   },
   "source": [
    "## Preparación\n",
    "\n",
    "Instale el paquete `tfds-nightly` para el conjunto de datos penguins. El paquete `tfds-nightly` es la versión nightly de los Conjuntos de Datos TensorFlow (TFDS). Para más información sobre TFDS, consulte [Descripción general de los conjuntos de datos TensorFlow](https://www.tensorflow.org/datasets/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XXWn1eDZmET"
   },
   "outputs": [],
   "source": [
    "!pip install -q tfds-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtGeMicKRGzU"
   },
   "source": [
    "A continuación, seleccione **Tiempo de ejecución &gt; Reiniciar tiempo de ejecución** en el menú Colab para reiniciar el tiempo de ejecución de Colab.\n",
    "\n",
    "No siga con el resto de este tutorial sin antes reiniciar el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9onjGZWZbA-"
   },
   "source": [
    "Importe TensorFlow y los demás módulos de Python necesarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jElLULrDhQZR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"TensorFlow Datasets version: \",tfds.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Px6KAg0Jowz"
   },
   "source": [
    "## Importar el conjunto de datos\n",
    "\n",
    "El conjunto de datos predeterminado [penguins/processed](https://www.tensorflow.org/datasets/catalog/penguins) ya está limpio, normalizado y listo para construir un modelo. Antes de descargar los datos procesados, previsualice una versión simplificada para familiarizarse con los datos originales del estudio sobre pingüinos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnX1-aLors4S"
   },
   "source": [
    "### Previsualizar los datos\n",
    "\n",
    "Descargue la versión simplificada del conjunto de datos de pingüinos (`penguins/simple`) usando el método [`tdfs.load`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) de Conjuntos de Datos TensorFlow. Hay 344 registros de datos en este conjunto de datos. Extraiga los cinco primeros registros en un objeto [`DataFrame`](https://www.tensorflow.org/datasets/api_docs/python/tfds/as_dataframe) para inspeccionar una muestra de los valores de este conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQvb_JYdrpPm"
   },
   "outputs": [],
   "source": [
    "ds_preview, info = tfds.load('penguins/simple', split='train', with_info=True)\n",
    "df = tfds.as_dataframe(ds_preview.take(5), info)\n",
    "print(df)\n",
    "print(info.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQhzD6P-uBoq"
   },
   "source": [
    "Las filas numeradas son registros de datos, un *[ejemplo](https://developers.google.com/machine-learning/glossary/#example)* por línea, donde:\n",
    "\n",
    "- Los seis primeros campos son *[características](https://developers.google.com/machine-learning/glossary/#feature)*: son las características de un ejemplo. Aquí, los campos contienen números que representan medidas de pingüinos.\n",
    "- La última columna es la *[etiqueta](https://developers.google.com/machine-learning/glossary/#label)*: es el valor que se quiere predecir. Para este conjunto de datos, es un valor entero de 0, 1 o 2 que corresponde al nombre de una especie de pingüino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCtwLoJhhDNc"
   },
   "source": [
    "En el conjunto de datos, la etiqueta de la especie de pingüino se representa como un número para que sea más fácil trabajar con ella en el modelo que construye. Estos números corresponden a las siguientes especies de pingüinos:\n",
    "\n",
    "- `0`: pingüino de Adelia\n",
    "- `1`: pingüino barbijo\n",
    "- `2`: pingüino gentú\n",
    "\n",
    "Cree una lista que contenga los nombres de las especies de pingüinos en este orden. Usará esta lista para interpretar los resultados del modelo de clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVNlJlUOhkoX"
   },
   "outputs": [],
   "source": [
    "class_names = ['Adélie', 'Chinstrap', 'Gentoo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iav9kEgxpY0s"
   },
   "source": [
    "Para saber más sobre características y etiquetas, consulte la [sección Terminología ML del Curso acelerado de aprendizaje automático](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD33PxSmCrtL"
   },
   "source": [
    "### Descargar el conjunto de datos preprocesados\n",
    "\n",
    "Ahora, descargue el conjunto de datos preprocesado de pingüinos (`penguins/processed`) con el método `tfds.load`, que devuelve una lista de objetos `tf.data.Dataset`. Tenga en cuenta que el conjunto de datos `penguins/processed` no viene con su propio conjunto de prueba, así que use una división 80:20 para [dividir el conjunto de datos completo](https://www.tensorflow.org/datasets/splits) en los conjuntos de entrenamiento y prueba. Usará el conjunto de datos de prueba más adelante para verificar su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVV96zIYYAi8"
   },
   "outputs": [],
   "source": [
    "ds_split, info = tfds.load(\"penguins/processed\", split=['train[:20%]', 'train[20%:]'], as_supervised=True, with_info=True)\n",
    "\n",
    "ds_test = ds_split[0]\n",
    "ds_train = ds_split[1]\n",
    "assert isinstance(ds_test, tf.data.Dataset)\n",
    "\n",
    "print(info.features)\n",
    "df_test = tfds.as_dataframe(ds_test.take(5), info)\n",
    "print(\"Test dataset sample: \")\n",
    "print(df_test)\n",
    "\n",
    "df_train = tfds.as_dataframe(ds_train.take(5), info)\n",
    "print(\"Train dataset sample: \")\n",
    "print(df_train)\n",
    "\n",
    "ds_train_batch = ds_train.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xX2NfLyQOK1y"
   },
   "source": [
    "Observe que esta versión del conjunto de datos se procesó reduciendo los datos a cuatro características normalizadas y una etiqueta de especie. En este formato, los datos pueden usarse rápidamente para entrenar un modelo sin más procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDuG94H-C122"
   },
   "outputs": [],
   "source": [
    "features, labels = next(iter(ds_train_batch))\n",
    "\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E63mArnQaAGz"
   },
   "source": [
    "Puede visualizar algunos clusters trazando algunas características del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me5Wn-9FcyyO"
   },
   "outputs": [],
   "source": [
    "plt.scatter(features[:,0],\n",
    "            features[:,2],\n",
    "            c=labels,\n",
    "            cmap='viridis')\n",
    "\n",
    "plt.xlabel(\"Body Mass\")\n",
    "plt.ylabel(\"Culmen Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsaVrtNM3Tx5"
   },
   "source": [
    "## Construir un modelo lineal simple\n",
    "\n",
    "### ¿Por qué un modelo?\n",
    "\n",
    "Un *[modelo](https://developers.google.com/machine-learning/crash-course/glossary#model)* es una relación entre las características y la etiqueta. Para resolver el problema de clasificación de pingüinos, el modelo define la relación entre las medidas de masa corporal, aletas y culmen y la especie de pingüino predicha. Algunos modelos sencillos pueden describirse con unas pocas líneas de álgebra, pero los modelos complejos de aprendizaje automático tienen un gran número de parámetros que son difíciles de resumir.\n",
    "\n",
    "¿Podría determinar la relación entre las cuatro características y la especie de pingüino *sin* usar el aprendizaje automático? Es decir, ¿podría usar técnicas de programación tradicionales (por ejemplo, muchas sentencias condicionales) para crear un modelo? Tal vez, si analizara el conjunto de datos el tiempo suficiente para determinar las relaciones entre la masa corporal y las medidas del culmen con una especie concreta. Y esto se hace difícil (quizá imposible) en conjuntos de datos más complicados. Un buen enfoque de aprendizaje automático *determina el modelo por usted*. Si le da suficientes ejemplos representativos al tipo de modelo de aprendizaje automático adecuado, el programa determina las relaciones por usted.\n",
    "\n",
    "### Elegir el modelo\n",
    "\n",
    "Después tiene que elegir el tipo de modelo que va a entrenar. Hay muchos tipos de modelos y elegir uno bueno requiere experiencia. Este tutorial usa una red neuronal para resolver el problema de clasificación de pingüinos. [*Las redes neuronales*](https://developers.google.com/machine-learning/glossary/#neural_network) pueden encontrar relaciones complejas entre las características y la etiqueta. Se trata de un grafo muy estructurado, organizado en una o varias [*capas ocultas*](https://developers.google.com/machine-learning/glossary/#hidden_layer). Cada capa oculta está formada por una o más [*neuronas*](https://developers.google.com/machine-learning/glossary/#neuron). Existen varias categorías de redes neuronales y este programa usa una red neuronal densa, o [*completamente conectada*](https://developers.google.com/machine-learning/glossary/#fully_connected_layer): las neuronas de una capa reciben conexiones de entrada de *cada* neurona de la capa anterior. Por ejemplo, la figura 2 ilustra una red neuronal densa formada por una capa de entrada, dos capas ocultas y una capa de salida:\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://www.tensorflow.org/tutorials/customization/images/full_network_penguin.png\" class=\"no-filter\" alt=\"Diagrama de la arquitectura de la red: Entradas, 2 capas ocultas y salidas\"> </td></tr>\n",
    "  <tr><td align=\"center\">     <b>Figura 2.</b> Una red neuronal con características, capas ocultas y predicciones.<br> </td></tr>\n",
    "</table>\n",
    "\n",
    "Cuando entrena el modelo de la Figura 2 y lo alimenta con un ejemplo sin etiquetar, produce tres predicciones: la probabilidad de que este pingüino sea de la especie dada. Esta predicción se llama [*inferencia*](https://developers.google.com/machine-learning/crash-course/glossary#inference). En este ejemplo, la suma de las predicciones de salida es 1.0. En la Figura 2, esta predicción se desglosa como `0.02` para la especie *de Adelia*, `0.95` para la especie *barbijo*, y `0.03` para la especie *gentú*. Esto significa que el modelo predice (con un 95 % de probabilidad) que un pingüino de ejemplo no etiquetado es un *pingüino Barbijo*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W23DIMVPQEBt"
   },
   "source": [
    "### Crear un modelo usando Keras\n",
    "\n",
    "La API TensorFlow `tf.keras` es la forma preferida de crear modelos y capas. Esto facilita la creación de modelos y la experimentación, a la vez que Keras se encarga de la complejidad de conectarlo todo.\n",
    "\n",
    "El modelo `tf.keras.Sequential` es una pila lineal de capas. Su constructor toma una lista de instancias de capas, en este caso, dos capas `tf.keras.layers.Dense` con 10 nodos cada una, y una capa de salida con 3 nodos para representar sus predicciones de etiquetas. El parámetro `input_shape` de la primera capa corresponde al número de características del conjunto de datos, y es obligatorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fZ6oL2ig3ZK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHcbEzMpxbHL"
   },
   "source": [
    "La [*función de activación*](https://developers.google.com/machine-learning/crash-course/glossary#activation_function) determina la forma de salida de cada nodo de la capa. Estas no linealidades son importantes: sin ellas, el modelo sería equivalente a una sola capa. Hay muchas `tf.keras.activations`, pero para las capas ocultas es común usar [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU).\n",
    "\n",
    "La cantidad ideal de capas ocultas y neuronas varía en función del problema y del conjunto de datos. Igual que muchos aspectos del aprendizaje automático, se requiere una mezcla de conocimientos y experimentación para elegir la mejor forma de la red neuronal. Como regla general, aumentar el número de capas ocultas y neuronas suele crear un modelo más potente, que requiere más datos para entrenarse eficazmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wFKnhWCpDSS"
   },
   "source": [
    "### Usar el modelo\n",
    "\n",
    "Veamos rápidamente lo que hace este modelo con un lote de funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe6SQ5NrpB-I"
   },
   "outputs": [],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxyXOhwVr5S3"
   },
   "source": [
    "Aquí, cada ejemplo devuelve un [logit](https://developers.google.com/machine-learning/crash-course/glossary#logits) para cada clase.\n",
    "\n",
    "Para convertir estos logits en una probabilidad para cada clase, use la función [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tRwHZmTNTX2"
   },
   "outputs": [],
   "source": [
    "tf.nn.softmax(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRZmchElo481"
   },
   "source": [
    "Si se toma el `tf.math.argmax` entre las clases, obtenemos el índice de clase predicho. Pero el modelo aún no se ha entrenado, así que no son buenas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Jzm_GoErz8B"
   },
   "outputs": [],
   "source": [
    "print(\"Prediction: {}\".format(tf.math.argmax(predictions, axis=1)))\n",
    "print(\"    Labels: {}\".format(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vzq2E5J2QMtw"
   },
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "El [*entrenamiento*](https://developers.google.com/machine-learning/crash-course/glossary#training) es la fase del aprendizaje automático en la que el modelo se optimiza gradualmente, es decir, el modelo *aprende* el conjunto de datos. La meta es que aprenda lo suficiente sobre la estructura del conjunto de datos de entrenamiento para hacer predicciones sobre datos que no haya visto. Si aprende *demasiado* sobre el conjunto de datos de entrenamiento, las predicciones sólo funcionarán para los datos que haya visto y no serán generalizables. Este problema se llama [*sobreajuste*](https://developers.google.com/machine-learning/crash-course/glossary#overfitting): es como memorizar las respuestas en lugar de comprender cómo resolver un problema.\n",
    "\n",
    "El problema de clasificación de pingüinos es un ejemplo de [*aprendizaje automático supervisado*](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning): el modelo se entrena a partir de ejemplos que contienen etiquetas. En el [*aprendizaje automático no supervisado*](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning), los ejemplos no contienen etiquetas. En su lugar, el modelo suele encontrar patrones entre las características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaKp8aEjKX6B"
   },
   "source": [
    "### Definir la pérdida y la función de gradientes\n",
    "\n",
    "Tanto en la fase de entrenamiento como en la de evaluación hay que calcular la [*pérdida*](https://developers.google.com/machine-learning/crash-course/glossary#loss) del modelo. Esto mide lo alejadas que están las predicciones de un modelo de la etiqueta deseada, en otras palabras, lo mal que funciona el modelo. Se desea minimizar, u optimizar, este valor.\n",
    "\n",
    "Su modelo calculará su pérdida usando la función `tf.keras.losses.SparseCategoricalCrossentropy` que toma las predicciones de probabilidad de clase del modelo y la etiqueta deseada, y devuelve la pérdida media en todos los ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOsi6b-1CXIn"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMAT4DcMPwI-"
   },
   "outputs": [],
   "source": [
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = model(x, training=training)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "l = loss(model, features, labels, training=False)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IcPqA24QM6B"
   },
   "source": [
    "Use el contexto `tf.GradientTape` para calcular los [*gradientes*](https://developers.google.com/machine-learning/crash-course/glossary#gradient) usados para optimizar su modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x57HcKWhKkei"
   },
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOxFimtlKruu"
   },
   "source": [
    "### Crear un optimizador\n",
    "\n",
    "Un [*optimizador*](https://developers.google.com/machine-learning/crash-course/glossary#optimizer) aplica los gradientes calculados a los parámetros del modelo para minimizar la función `loss`. Imagine la función loss como una superficie curva (vea la Figura 3) y quiere encontrar su punto más bajo andando a su alrededor. Los gradientes apuntan en la dirección del ascenso más pronunciado, así que se desplazará en sentido contrario y bajará por la colina. Calculando iterativamente la pérdida y el gradiente para cada lote, ajustará el modelo durante el entrenamiento. Gradualmente, el modelo encontrará la mejor combinación de ponderaciones y sesgo para minimizar la pérdida. Y cuanto menor sea la pérdida, mejores serán las predicciones del modelo.\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\" alt=\"Algoritmos de optimización visualizados en el tiempo en un espacio 3D.\"> </td></tr>\n",
    "  <tr><td align=\"center\">     <b>Figura 3.</b> Algoritmos de optimización visualizados en el tiempo en un espacio 3D.<br>(Fuente: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, licencia del MIT, Créditos de imagen: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)</td></tr>\n",
    "</table>\n",
    "\n",
    "TensorFlow tiene muchos algoritmos de optimización disponibles para el entrenamiento. En este tutorial, usará `tf.keras.optimizers.SGD` que implementa el algoritmo [*descenso de gradiente estocástico*](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent) (SGD). El parámetro `learning_rate` fija el tamaño del paso que hay que dar en cada iteración cuesta abajo. Esta tasa es un [*hiperparámetro*](https://developers.google.com/machine-learning/glossary/#hyperparameter) que deberá ajustar habitualmente para obtener mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkUd6UiZa_dF"
   },
   "source": [
    "Instancie el optimizador con una [*velocidad de aprendizaje*](https://developers.google.com/machine-learning/glossary#learning-rate) de `0.01`, un valor escalar que se multiplica por el gradiente en cada iteración del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xxi2NNGKwG_"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJVRZ0hP52ZB"
   },
   "source": [
    "A continuación, use este objeto para calcular un único paso de optimización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxRNTFVe56RG"
   },
   "outputs": [],
   "source": [
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss(model, features, labels, training=True).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Y2VSELvwAvW"
   },
   "source": [
    "### Bucle de entrenamiento\n",
    "\n",
    "Con todas las piezas en su sitio, ¡el modelo está listo para ser entrenado! Un bucle de entrenamiento alimenta el modelo con los ejemplos del conjunto de datos para ayudarle a hacer mejores predicciones. El siguiente bloque de código establece estos pasos de entrenamiento:\n",
    "\n",
    "1. Itere cada *epoca*. Una época es una pasada por el conjunto de datos.\n",
    "2. Dentro de una época, itere sobre cada ejemplo del `Dataset` de entrenamiento tomando sus *características* (`x`) y *etiqueta* (`y`).\n",
    "3. Usando las características del ejemplo, haga una predicción y compárela con la etiqueta. Mida la inexactitud de la predicción y úsela para calcular la pérdida y los gradientes del modelo.\n",
    "4. Use un `optimizer` para actualizar los parámetros del modelo.\n",
    "5. Conserve algunas estadísticas para visualizarlas.\n",
    "6. Repítalo para cada época.\n",
    "\n",
    "La variable `num_epochs` es el número de veces que se repite el bucle sobre la colección de conjuntos de datos. En el siguiente código, `num_epochs` se fija en 201, lo que significa que este bucle de entrenamiento se ejecutará 201 veces. Aunque parezca contradictorio, entrenar un modelo durante más tiempo no garantiza un mejor modelo. `num_epochs` es un [*hiperparámetro*](https://developers.google.com/machine-learning/glossary/#hyperparameter) que puede ajustar. Seleccionar el número adecuado suele requerir experiencia y experimentación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIgulGRUhpto"
   },
   "outputs": [],
   "source": [
    "## Note: Rerunning this cell uses the same model parameters\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in ds_train_batch:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    # training=True is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "  # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 50 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diep-ROEuKyl"
   },
   "source": [
    "También puede usar el método incorporado [`Model.fit(ds_train_batch)`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) de Keras para entrenar su modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FQHVUnm_rjw"
   },
   "source": [
    "### Ver la función de pérdida en el tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3wdbmtLVTyr"
   },
   "source": [
    "Aunque es útil imprimir el progreso del entrenamiento del modelo, puede visualizarlo con [TensorBoard](https://www.tensorflow.org/tensorboard), una herramienta de visualización y métricas que viene incluida con TensorFlow. Para este sencillo ejemplo, usará el módulo `matplotlib` para crear gráficos básicos.\n",
    "\n",
    "Hay que aprender a interpretar estos gráficos, pero en general lo que se desea es que disminuya la *pérdida* y aumente la *precisión*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agjvNd2iUGFn"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg8GoMZhLpGH"
   },
   "source": [
    "## Evaluar la eficacia del modelo\n",
    "\n",
    "Ahora que el modelo está entrenado, puede sacar algunas estadísticas sobre su rendimiento.\n",
    "\n",
    "*Evaluar* significa determinar la eficacia del modelo a la hora de hacer predicciones. Para determinar la eficacia del modelo en la clasificación de pingüinos, pásele algunas mediciones y pídale que prediga qué especie de pingüino representan. Luego compare sus predicciones con la etiqueta real. Por ejemplo, un modelo que eligió la especie correcta en la mitad de los ejemplos de entrada tiene una [*precisión*](https://developers.google.com/machine-learning/glossary/#accuracy) de `0.5`. La figura 4 muestra un modelo ligeramente más eficaz, que acierta 4 de cada 5 predicciones con una precisión del 80%:\n",
    "\n",
    "<table cellpadding=\"8\" border=\"0\">\n",
    "  <colgroup>\n",
    "    <col span=\"4\">\n",
    "    <col span=\"1\" bgcolor=\"lightblue\">\n",
    "    <col span=\"1\" bgcolor=\"lightgreen\">\n",
    "  </colgroup>\n",
    "  <tr bgcolor=\"lightgray\">\n",
    "    <th colspan=\"4\">Características de ejemplo</th>\n",
    "    <th colspan=\"1\">Etiqueta</th>\n",
    "    <th colspan=\"1\">Predicción del modelo</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.9</td>\n",
    "<td>3.0</td>\n",
    "<td>4.3</td>\n",
    "<td>1.5</td>\n",
    "<td align=\"center\">1</td>\n",
    "<td align=\"center\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6.9</td>\n",
    "<td>3.1</td>\n",
    "<td>5.4</td>\n",
    "<td>2.1</td>\n",
    "<td align=\"center\">2</td>\n",
    "<td align=\"center\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.1</td>\n",
    "<td>3.3</td>\n",
    "<td>1.7</td>\n",
    "<td>0.5</td>\n",
    "<td align=\"center\">0</td>\n",
    "<td align=\"center\">0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6.0</td> <td>3.4</td> <td>4.5</td> <td>1.6</td> <td align=\"center\">1</td>\n",
    "<td align=\"center\" bgcolor=\"red\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5.5</td>\n",
    "<td>2.5</td>\n",
    "<td>4.0</td>\n",
    "<td>1.3</td>\n",
    "<td align=\"center\">1</td>\n",
    "<td align=\"center\">1</td>\n",
    "  </tr>\n",
    "  <tr><td align=\"center\" colspan=\"6\">     <b>Figura 4.</b> Un clasificador de pingüinos con un 80% de precisión.<br> </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-EvK7hGL0d8"
   },
   "source": [
    "### Configurar el conjunto de pruebas\n",
    "\n",
    "Evaluar el modelo es similar a entrenarlo. La mayor diferencia es que los ejemplos vienen de un *[conjunto de prueba](https://developers.google.com/machine-learning/crash-course/glossary#test_set)* distinto del conjunto de entrenamiento. Si quiere evaluar correctamente la eficacia de un modelo, los ejemplos usados para evaluarlo deben ser distintos de los usados para entrenarlo.\n",
    "\n",
    "El conjunto de datos de pingüinos no tiene un conjunto de datos de prueba separado, así que, en la sección anterior Descargar el conjunto de datos, divida el conjunto de datos original en conjuntos de datos de prueba y de entrenamiento. Use el conjunto de datos `ds_test_batch` para la evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFuOKXJdMAdm"
   },
   "source": [
    "### Evaluar el modelo en el conjunto de datos de prueba\n",
    "\n",
    "A diferencia de la etapa de entrenamiento, el modelo sólo evalúa una única [época](https://developers.google.com/machine-learning/glossary/#epoch) de los datos de prueba. El código siguiente itera sobre cada ejemplo del conjunto de prueba y compara la predicción del modelo con la etiqueta real. Esta comparación se usa para medir la precisión del modelo en todo el conjunto de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw03-MK1cYId"
   },
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "ds_test_batch = ds_test.batch(10)\n",
    "\n",
    "for (x, y) in ds_test_batch:\n",
    "  # training=False is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  logits = model(x, training=False)\n",
    "  prediction = tf.math.argmax(logits, axis=1, output_type=tf.int64)\n",
    "  test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fel8ql2qzGlK"
   },
   "source": [
    "También puede usar la función `model.evaluate(ds_test, return_dict=True)` de keras para conseguir información de qué tan preciso es su conjunto de datos de prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcKEZMtCOeK-"
   },
   "source": [
    "Al inspeccionar el último lote, por ejemplo, puede ver que las predicciones del modelo suelen ser correctas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNwt2eMeOane"
   },
   "outputs": [],
   "source": [
    "tf.stack([y,prediction],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Li2r1tYvW7S"
   },
   "source": [
    "## Usar el modelo entrenado para hacer predicciones\n",
    "\n",
    "Ha entrenado un modelo y \"demostrado\" que es bueno (pero no perfecto) para clasificar las especies de pingüinos. Ahora vamos a usar el modelo entrenado para hacer algunas predicciones con [*ejemplos sin etiquetar*](https://developers.google.com/machine-learning/glossary/#unlabeled_example); es decir, con ejemplos que tienen características pero no etiquetas.\n",
    "\n",
    "En la vida real, los ejemplos sin etiquetar pueden venir de muchas fuentes distintas, como apps, archivos CSV y fuentes de datos. Para este tutorial, le damos manualmente tres ejemplos sin etiquetar para predecir sus etiquetas. Recuerde que los números de etiqueta se mapean en una representación con nombre como:\n",
    "\n",
    "- `0`: pingüino de Adelia\n",
    "- `1`: pingüino barbijo\n",
    "- `2`: pingüino gentú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kesTS5Lzv-M2"
   },
   "outputs": [],
   "source": [
    "predict_dataset = tf.convert_to_tensor([\n",
    "    [0.3, 0.8, 0.4, 0.5,],\n",
    "    [0.4, 0.1, 0.8, 0.5,],\n",
    "    [0.7, 0.9, 0.8, 0.4]\n",
    "])\n",
    "\n",
    "# training=False is needed only if there are layers with different\n",
    "# behavior during training versus inference (e.g. Dropout).\n",
    "predictions = model(predict_dataset, training=False)\n",
    "\n",
    "for i, logits in enumerate(predictions):\n",
    "  class_idx = tf.math.argmax(logits).numpy()\n",
    "  p = tf.nn.softmax(logits)[class_idx]\n",
    "  name = class_names[class_idx]\n",
    "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucMoYase6URl"
   },
   "source": [
    "# Carga y procesamiento de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxw4WahM7DU9"
   },
   "source": [
    "En este tutorial se muestra cómo cargar y preprocesar un conjunto de datos de imágenes de tres formas:\n",
    "\n",
    "- Primero, usarás las utilidades de preprocesamiento de alto nivel de Keras (como `tf.keras.utils.image_dataset_from_directory`) y capas (como `tf.keras.layers.Rescaling`) para leer un directorio de imágenes en un disco.\n",
    "- Luego, escribirá su propia canalización de entrada desde cero [con tf.data](../../guide/data.ipynb).\n",
    "- Por último, descargará un conjunto de datos de un [catálogo](https://www.tensorflow.org/datasets/catalog/overview) más grande que está disponible en [TensorFlow Datasets](https://www.tensorflow.org/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoQQiZDB6URn"
   },
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vhAMaIOBIee"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qnp9Z2sT5dWj"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO0InzL66URu"
   },
   "source": [
    "### Descargar el conjunto de datos de flores\n",
    "\n",
    "Este tutorial usa un conjunto de datos de miles de fotos de flores. El conjunto de datos de flores contiene cinco subdirectorios, uno por clase.\n",
    "\n",
    "```\n",
    "flowers_photos/\n",
    "  daisy/\n",
    "  dandelion/\n",
    "  roses/\n",
    "  sunflowers/\n",
    "  tulips/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju2yXtdV5YaT"
   },
   "source": [
    "Nota: todas las imágenes son licencia de CC-BY, los creadores están en el archivo LICENSE.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rN-Pc6Zd6awg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "# Descargar y extraer el dataset en el directorio actual\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True, cache_dir=\".\")\n",
    "\n",
    "# Ajustar la ruta al directorio extraído\n",
    "data_dir = pathlib.Path(archive).with_suffix('.tgz') / \"flower_photos\"\n",
    "print (data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFkFK74oO--g"
   },
   "source": [
    "Después de la descarga (218MB), debería tener una copia disponible de las fotos de flores. Son 3670 imágenes en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhewYCxhXQBX"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUFusk44d9GW"
   },
   "source": [
    "Cada directorio contiene imágenes de ese tipo de flor. Estas son algunas rosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crs7ZjEp60Ot"
   },
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oV9PtjdKKWyI"
   },
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_kge08gSCan"
   },
   "source": [
    "## Cargar datos con una utilidad de Keras\n",
    "\n",
    "Carguemos estas imágenes fuera del disco con la utilidad `tf.keras.utils.image_dataset_from_directory` que es muy útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jobDTUs8Wxu"
   },
   "source": [
    "### Crear un conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAmtzsnjDNhB"
   },
   "source": [
    "Defina algunos parámetros para el cargador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJdpyqK541ty"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehhW308g8soJ"
   },
   "source": [
    "Se considera buena práctica usar un separador de validación al desarrollar el modelo. El 80 % de las imágenes las usará para entrenamiento y el 20 % para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chqakIP14PDm"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb2Af2lsUShk"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug3ITsz0b_cF"
   },
   "source": [
    "En estos conjuntos de datos, puede encontrar los nombres de clase en el atributo `class_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7z2yKt7VDPJ"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK6CQCqIctCd"
   },
   "source": [
    "### Visualizar los datos\n",
    "\n",
    "Aquí están las primeras nueve imágenes del conjunto de datos para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAY3LJN28Kuy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUI0fr7igPtA"
   },
   "source": [
    "Puede entrenar un modelo con estos conjuntos de datos al pasarlos a `model.fit` (lo veremos más adelante). Si quiere, también puede iterar manualmente por los conjuntos de datos y recuperar lotes de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdPHeHXt9sjA"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZgIZeXaDUsF"
   },
   "source": [
    "El lote de imagen `image_batch` es un tensor de la forma `(32, 180, 180, 3)`. Esto es un lote de 32 imágenes de forma `180x180x3` (la última dimensión hace referencia a los canales de color RGB). El lote `label_batch` es un tensor de la forma `(32,)`, estas son etiquetas que concuerdan con las 32 imágenes.\n",
    "\n",
    "Se puede llamar a `.numpy()` en cualquiera de estos tensores para convertirlos en `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybl6a2YCg1rV"
   },
   "source": [
    "### Estandarizar los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdogGjM2K6OU"
   },
   "source": [
    "Los valores del canal RGB están dentro del rango `[0, 255]`, lo cual no es ideal para una red neuronal. En general, debería buscar que los valores de su entrada sean bajos.\n",
    "\n",
    "Aquí, estandarizará los valores para que estén dentro del rango `[0, 1]` mediante el uso de `tf.keras.layers.Rescaling`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16yNdZXdExyM"
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd0_enkb8uxZ"
   },
   "source": [
    "Esta capa se puede usar de dos formas. Se puede aplicar en el conjunto de datos llamando `Dataset.map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgOnza-U_z5Y"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z39nXayj9ioS"
   },
   "source": [
    "O, se puede incluir la capa en la definición de su modelo para simplificar la implementación. Aquí se usará el segundo enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXLd3wMpDIkp"
   },
   "source": [
    "Nota: Si lo que quiere es escalar valores de píxeles a `[-1,1]` escriba `tf.keras.layers.Rescaling(1./127.5, offset=-1)` en su lugar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeNWVa8qRBGm"
   },
   "source": [
    "Nota: Previamente, usaste el argumento `image_size` de `tf.keras.utils.image_dataset_from_directory` para ajustar el tamaño de las imágenes. Si también quiere incluir la lógica del ajuste en su modelo, puede usar la capa `tf.keras.layers.Resizing`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti8avTlLofoJ"
   },
   "source": [
    "### Configurar el conjunto de datos para rendimiento\n",
    "\n",
    "Vamos a asegurarnos de usar una preextracción almacenada en el búfer para que pueda producir datos desde el disco sin provocar un bloqueo en la E/S. Hay dos métodos importantes que deberías usar al cargar datos:\n",
    "\n",
    "- `Dataset.cache` conserva los datos en la memoria después de que se carga desde el disco durante la primera época. Así se garantiza que el conjunto de datos no se transforme en un cuello de botella mientras entrena su modelo. Si su conjunto de datos es muy grande para guardar en la memoria, también puede usar este método para crear un caché en disco de alto rendimiento.\n",
    "- `Dataset.prefetch` superpone el preprocesamiento de los datos y la ejecución del modelo durante el entrenamiento.\n",
    "\n",
    "Quienes quieran aprender más sobre ambos modelos y también sobre cómo copiar datos en caché en disco, pueden leer la sección *Preextracción* de la guía [Mejor rendimiento con la API tf.data](../../guide/data_performance.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea3kbMe-pGDw"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqHjIr6cplwY"
   },
   "source": [
    "### Entrenar un modelo\n",
    "\n",
    "Para completar el tutorial, deberá mostrar cómo entrenar un modelo simple con los conjuntos de datos que acaba de preparar.\n",
    "\n",
    "El modelo [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) consiste en tres bloques de convolución (`tf.keras.layers.Conv2D`) con una capa de agrupación máxima (`tf.keras.layers.MaxPooling2D`) en cada uno de ellos. Hay una capa totalmente conectada (`tf.keras.layers.Dense`) con 128 unidades más que se activa con una función de activación de ReLU (`'relu'`). El modelo no tiene ningún ajuste, el objetivo es mostrarle los mecanismos con los conjuntos de datos que usted acaba de crear. Para aprender más sobre la clasificación de imágenes, vea el tutorial de [Clasificación de imágenes](../images/classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdR0BzCcqxw0"
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d83f5aa7f3fb"
   },
   "source": [
    "Escoja el optimizador `tf.keras.optimizers.Adam` y la función de pérdida `tf.keras.losses.SparseCategoricalCrossentropy`. Para ver la precisión de entrenamiento y validación de cada época de entrenamiento, realice una pasada del argumento de `métricas` en `Model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_BlmsnmsEr4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compila con:\n",
    "# - Optimizer: Adam\n",
    "# - Métrica: accuracy\n",
    "model.______(\n",
    "    optimizer=______,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=______\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffwd44ldNMOE"
   },
   "source": [
    "Nota: Solo lo entrenará para algunas épocas para que el tutorial se ejecute rápido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S08ZKKODsnGW"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEtT9YGjSAOK"
   },
   "source": [
    "Nota: También puede escribir un bucle de entrenamiento personalizado en vez de usar `Model.fit`. Para más información, visite el tutorial de [Escribir un bucle desde cero](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaW4wx5L7hrZ"
   },
   "source": [
    "Quizás notará que la precisión de la validación es baja en comparación con la precisión del entrenamiento, esto quiere decir que su modelo está sobreajustado. Puede obtener más información sobre sobrejuste y sobre cómo reducirlo en este [tutorial](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxS1cLzM8mEp"
   },
   "source": [
    "## El uso de tf.data para control más preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylj9fgkamgWZ"
   },
   "source": [
    "La utilidad de preprocesamiento de Keras mencionada anteriormente, `tf.keras.utils.image_dataset_from_directory`, es una forma conveniente de crear un `tf.data.Dataset` desde una directorio de imágenes.\n",
    "\n",
    "Para control más preciso y específico, puede escribir su propia canalización de entrada con `tf.data`. En esta sección se muestra cómo hacerlo, empezando con las rutas de archivo del archivo TGZ que descargó antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAkQp5uxoINu"
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coORvEH-NGwc"
   },
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NLQ_VJhWO4z"
   },
   "source": [
    "La estructura de árbol de estos archivos puede usarse para compilar una lista `class_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRPHzDGhKACK"
   },
   "outputs": [],
   "source": [
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiptrWmAlmAa"
   },
   "source": [
    "Divida los conjuntos de datos en conjuntos de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWHNPzXclpVr"
   },
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkB-IR4-pS3U"
   },
   "source": [
    "Puede imprimir la longitud de cada conjunto de datos como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiKQrb9ppS-7"
   },
   "outputs": [],
   "source": [
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91CPfUUJ_8SZ"
   },
   "source": [
    "Escriba una función breve que convierta una ruta de archivo en una pareja `(img, label)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arSQzIey-4D4"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # Convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  one_hot = parts[-2] == class_names\n",
    "  # Integer encode the label\n",
    "  return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGlq4IP4Aktb"
   },
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xhBRgvNqRRe"
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9a5GpsUOBx8"
   },
   "source": [
    "Use `Dataset.map` para crear un conjunto de datos de parejas de `image, label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SDhbo8lOBQv"
   },
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxrl0lGdnpRz"
   },
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYGCgJuR_9Qp"
   },
   "source": [
    "### Configurar conjuntos de datos para rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwZavzgsIytz"
   },
   "source": [
    "Para entrenar un modelo con este conjunto de datos, necesita que los datos:\n",
    "\n",
    "- Estén en orden aleatorio.\n",
    "- Estén en lotes.\n",
    "- Que los lotes estén disponibles lo antes posible.\n",
    "\n",
    "Se pueden agregar estas características con la API `tf.data`. Para más información, lea la guía [Input Pipeline Performance](../../guide/performance/datasets.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZmZJx8ePw_5"
   },
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45P7OvzRWzOB"
   },
   "source": [
    "### Visualizar los datos\n",
    "\n",
    "Puede visualizar estos conjuntos de datos de forma similar a como lo hizo previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UN_Dnl72YNIj"
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "  label = label_batch[i]\n",
    "  plt.title(class_names[label])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMT8kh_uXPRU"
   },
   "source": [
    "### Continuar entrenando el modelo\n",
    "\n",
    "Ahora ha construido un `tf.data.Dataset` parecido al de `tf.keras.utils.image_dataset_from_directory` anteriormente. Puede continuar entrenándolo con ese modelo. Igual que antes, solo lo entrenará para algunas épocas para que el tiempo de ejecución sea corto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vm_bi7NKXOzW"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDJXAexrwsx8"
   },
   "source": [
    "## El uso de TensorFlow Datasets\n",
    "\n",
    "Por ahora, este tutorial solo se ha enfocado en cargar datos fuera del disco. También puede encontrar conjuntos de datos para usar si explora el gran [catálogo](https://www.tensorflow.org/datasets/catalog/overview) de conjuntos de datos de fácil descarga en  [TensorFlow Datasets](https://www.tensorflow.org/datasets).\n",
    "\n",
    "Previamente, ya cargó el conjunto de datos de flores fuera del disco, ahora lo vamos a importar con TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qyu9wWDf1gfH"
   },
   "source": [
    "Descargue el [conjunto de datos](https://www.tensorflow.org/datasets/catalog/tf_flowers) de flores con TensorFlow Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTQ-53DNwv8o"
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hxXSgtj1iLV"
   },
   "source": [
    "El conjunto de datos de flores tiene cinco clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJvt6qzF1i4L"
   },
   "outputs": [],
   "source": [
    "num_classes = metadata.features['label'].num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dbvEz_F1lgE"
   },
   "source": [
    "Recupere una imagen del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lF3IUAO1ogi"
   },
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "image, label = next(iter(train_ds))\n",
    "_ = plt.imshow(image)\n",
    "_ = plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHOOH_4TwaUb"
   },
   "source": [
    "Igual que antes, recuerde que los conjuntos de entrenamiento, validación y prueba deben estar en lotes, en orden aleatorio y configurados para buen rendimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMV6GtZiwfGP"
   },
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmR7kT8l1w20"
   },
   "source": [
    "Puede encontrar un ejemplo completo que usa el conjunto de datos de flores y TensorFlow Datasets en el tutorial de [Aumento de datos](../images/data_augmentation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 255. \n",
    "\n",
    "In this example, each image will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset parameters.\n",
    "num_classes = 10 # total classes (0-9 digits).\n",
    "num_features = 784 # data features (img shape: 28*28).\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.1\n",
    "training_steps = 2000\n",
    "batch_size = 256\n",
    "display_step = 100\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 128 # 1st layer number of neurons.\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MNIST data.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Flatten images to 1-D vector of 784 features (28*28).\n",
    "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on validation set.\n",
    "pred = neural_net(x_test, is_training=False)\n",
    "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 5 images from validation set.\n",
    "n_images = 5\n",
    "test_images = x_test[:n_images]\n",
    "predictions = neural_net(test_images)\n",
    "\n",
    "# Display image and model prediction.\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction: %i\" % np.argmax(predictions.numpy()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZJ3uY9O17VN"
   },
   "source": [
    "# Guardar y cargar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdde4YJeJKF"
   },
   "source": [
    "El progreso del modelo se puede guardar durante y después del entrenamiento. Esto significa que un modelo puede reanudarse donde quedó y, de este modo, evitar tiempos de entrenamiento prolongados. La posibilidad de guardar también implica que puede compartir su modelo y los demás pueden recrear su trabajo. A la hora de publicar modelos y técnicas de investigación, la mayoría de los profesionales del aprendizaje automático comparten lo siguiente:\n",
    "\n",
    "- el código para crear el modelo, y\n",
    "- los pesos entrenados, o parámetros, del modelo\n",
    "\n",
    "Al compartir estos datos, se ayuda a los demás a comprender cómo funciona el modelo para que lo puedan probar por sí mismos con nuevos datos.\n",
    "\n",
    "Precaución: Los modelos de TensorFlow están cifrados y es importante que tenga cuidado con los códigos que no sean confiables. Consulte [Usar TensorFlow de forma segura](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) para obtener más información.\n",
    "\n",
    "### Opciones\n",
    "\n",
    "Existen distintas formas de guardar modelos de TensorFlow en función de la API que esté usando. Esta guía usa [tf.keras](https://www.tensorflow.org/guide/keras), una API de alto nivel que se usa para desarrollar y entrenar modelos en TensorFlow. Se recomienda el nuevo formato de alto nivel de `.keras` que se utiliza en este tutorial para guardar objetos de Keras, ya que ofrece un guardado sólido y eficiente basado en nombres que a menudo es más fácil de depurar que los formatos de bajo nivel o heredados. Para flujos de trabajo de guardado o serialización más avanzados, especialmente los que involucran objetos personalizados, consulte la [guía Guardar y cargar modelos de Keras](https://www.tensorflow.org/guide/keras/save_and_serialize). Por otros enfoques, consulte la [guía Usar el formato SavedModel](../../guide/saved_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCUREq7WXgvg"
   },
   "source": [
    "## Preparar\n",
    "\n",
    "### Instalaciones e importaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l0MiTOrXtNv"
   },
   "source": [
    "Instale e importe TensorFlow y las dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzIOVSdnMYyO"
   },
   "outputs": [],
   "source": [
    "!pip install pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Nm7Tyb-gRt-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbGsznErXWt6"
   },
   "source": [
    "### Obtener un conjunto de datos de ejemplo\n",
    "\n",
    "Usaremos el [conjunto de datos MNIST](http://yann.lecun.com/exdb/mnist/) para demostrar cómo guardar y cargar los pesos. Para acelerar estas ejecuciones, use los primeros 1000 ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rGfFwE9XVwz"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anG3iVoXyZGI"
   },
   "source": [
    "### Definir un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wynsOBfby0Pa"
   },
   "source": [
    "Para comenzar, genere un modelo secuencial simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HZbJIjxyX1S"
   },
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soDE0W_KH8rG"
   },
   "source": [
    "## Guardar puntos de verificación durante el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRyd5qQQIXZm"
   },
   "source": [
    "Puede usar un modelo entrenado sin necesidad de volver a entrenarlo o reanudar un entrenamiento donde lo dejó, en caso de que se haya interrumpido el proceso de entrenamiento. La retrollamada `tf.keras.callbacks.ModelCheckpoint` le permite guardar continuamente el modelo tanto *durante* el entrenamiento como *al final*.\n",
    "\n",
    "### Uso de la retrollamada de punto de verificación\n",
    "\n",
    "Cree una retrollamada  `tf.keras.callbacks.ModelCheckpoint` que guarde los pesos solo durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFPuhwntH8VH"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "\n",
    "# === ENTRENAMIENTO CON VALIDACIÓN ===\n",
    "# Entrena el modelo con datos de validación\n",
    "model.fit(\n",
    "    ______,\n",
    "    validation_data=(_____ , _____),\n",
    "    epochs=10,\n",
    "    callbacks=[cp_callback]\n",
    ")\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlM-sgyJO084"
   },
   "source": [
    "Esta acción crea una única colección de archivos de puntos de verificación de TensorFlow que se actualiza al final de cada época:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXG5FVKFOVQ3"
   },
   "outputs": [],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlRN_f56Pqa9"
   },
   "source": [
    "Siempre y cuando dos modelos compartan la misma arquitectura, podrá compartir los pesos entre ambos. Por lo tanto, al restaurar un modelo solo a partir de los pesos, cree un modelo con la misma arquitectura que el modelo original y, luego, configure sus pesos.\n",
    "\n",
    "A continuación, vuelva a generar un modelo sin entrenar y evalúelo en el conjunto de prueba. Un modelo sin entrenar se ejecutará a niveles de azar (~10 % de precisión):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fp5gbuiaPqCT"
   },
   "outputs": [],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "# === EVALUACIÓN ===\n",
    "# Evalúa el modelo con los datos de test\n",
    "loss, acc =  model.evaluate( ____ , ____ , verbose=2)\n",
    "\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DTKpZssRSo3"
   },
   "source": [
    "Luego, cargue los pesos del punto de verificación y vuelva a evaluar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IZxbwiRRSD2"
   },
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# === Re - EVALUACIÓN del modelo ===\n",
    "# Evalúa el modelo con los datos de test\n",
    "___ , ___ =  model.evaluate( test_images , test_labels , verbose=2)\n",
    "\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpAbKkAyVPV8"
   },
   "source": [
    "### Opciones de la retrollamada de punto de verificación\n",
    "\n",
    "La retrollamada ofrece varias opciones para otorgar nombres únicos a los puntos de verificación y ajustar la frecuencia de creación de puntos de verificación.\n",
    "\n",
    "Entrene un nuevo modelo y guarde puntos de verificación con nombres únicos cada cinco épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQF_dlgIVOvq"
   },
   "outputs": [],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training_1/cp-{epoch:04d}.weights.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Calculate the number of batches per epoch\n",
    "import math\n",
    "n_batches = len(train_images) / batch_size\n",
    "n_batches = math.ceil(n_batches)    # round up the number of batches to the nearest whole integer\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*n_batches)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          batch_size=batch_size, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images, test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zFrKTjjavWI"
   },
   "source": [
    "Ahora, revise los puntos de verificación resultantes y elija el último:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p64q3-V4sXt0"
   },
   "outputs": [],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AN_fnuyR41H"
   },
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOGlxPRBEvV1"
   },
   "source": [
    "## Guardar el modelo completo\n",
    "\n",
    "Llame `tf.keras.Model.save` para guardar la configuración de la arquitectura, los pesos y el entrenamiento de un modelo en un único archivo zip `model.keras`.\n",
    "\n",
    "Se puede guardar un modelo completo en tres formatos de archivo diferentes (el nuevo formato `.keras` y dos formatos heredados: `SavedModel` y `HDF5`). Si guarda un modelo como `path/to/model.keras` se guarda automáticamente en el formato más reciente.\n",
    "\n",
    "**Nota:** Para los objetos de Keras se recomienda usar el formato `.keras` de alto nivel, para guardar y recargar de forma más completa y basada en nombres, lo cual facilita la depuración. El formato SavedModel de bajo nivel y el formato H5 heredado aún son compatibles con el código existente.\n",
    "\n",
    "Si desea cambiar al formato SavedModel, haga lo siguiente:\n",
    "\n",
    "- Pase `save_format='tf'` a `save()`\n",
    "- Pase un nombre de archivo sin extensión\n",
    "\n",
    "Si desea cambiar al formato H5, haga lo siguiente:\n",
    "\n",
    "- Pase `save_format='h5'` a `save()`\n",
    "- Pase un nombre de archivo que termine en `.h5`\n",
    "\n",
    "Guardar un modelo completamente funcional es muy útil, puede cargarlo en TensorFlow.js ([Saved Model](https://www.tensorflow.org/js/tutorials/conversion/import_saved_model), [HDF5](https://www.tensorflow.org/js/tutorials/conversion/import_keras)) y luego entrenarlo y ejecutarlo en navegadores web o convertirlo para ejecutarlo en dispositivos móviles mediante el uso de TensorFlow Lite ([Saved Model](https://www.tensorflow.org/lite/models/convert/#convert_a_savedmodel_recommended_), [HDF5](https://www.tensorflow.org/lite/models/convert/#convert_a_keras_model_))\n",
    "\n",
    "*Los objetos personalizados (por ejemplo, los modelos o las capas subclasificados) requieren atención especial a la hora de guardarlos y cargarlos. Consulte la sección **Guardar objetos personalizados** que se describe más abajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fRGnlHMrkI7"
   },
   "source": [
    "### Nuevo formato `.keras` de alto nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqO8jj7GsCDn"
   },
   "source": [
    "El nuevo formato de guardado Keras v3, que se marca con la extensión `.keras`, es un formato más simple y eficiente que implementa un método de guardado basado en nombres, lo que le garantiza que lo que carga es exactamente lo que guardó, desde la perspectiva de Python. Esto simplifica mucho la tarea de depuración y constituye el formato recomendado para Keras.\n",
    "\n",
    "La siguiente sección ilustra el método de guardado y restauración del modelo en el formato `.keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f55mAXwukUX"
   },
   "outputs": [],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "\n",
    "# Guarda el modelo completo en formato Keras\n",
    "______.save('my_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHqwaun5g8lD"
   },
   "source": [
    "Vuelva a cargar un modelo Keras actualizado desde el archivo zip `.keras`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyfUMOZwux_-"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('my_model.keras')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Cn3pSBqvJ5f"
   },
   "source": [
    "Intente ejecutar la evaluación y predecir con el modelo cargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BT4mHNIvMdW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# === EVALUACIÓN ===\n",
    "# Evalúa el modelo con los datos de test\n",
    "___ , ___ =  model.evaluate( test_images , test_labels , verbose=2)\n",
    "\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "# === PREDICCIÓN ===\n",
    "# Realiza una predicción con el modelo \n",
    "\n",
    "print(new_model._____(_____).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWwgNaz19TH2"
   },
   "source": [
    "El modelo restaurado se compila con los mismos argumentos que el modelo original. Intente ejecutar la evaluación y con el modelo cargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yh5Mu0yOgE5J"
   },
   "outputs": [],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkGwf-50zLNn"
   },
   "source": [
    "### Formato HDF5\n",
    "\n",
    "Keras ofrece un formato de guardado de alto nivel heredado básico que usa el estándar [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2dkmJVCGUia"
   },
   "outputs": [],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWmttMOqS68S"
   },
   "source": [
    "Ahora bien, recree el modelo a partir de ese archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NDMO_7kS6Do"
   },
   "outputs": [],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXQpbTicTBwt"
   },
   "source": [
    "Compruebe su precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwEaj9DnTCVA"
   },
   "outputs": [],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGXqd4wWJl8O"
   },
   "source": [
    "Keras guarda modelos mediante la inspección de sus arquitecturas. Esta técnica guarda todo:\n",
    "\n",
    "- Los valores de peso\n",
    "- La arquitectura del modelo\n",
    "- La configuración de entrenamiento del modelo (lo que le pasa al método `.compile()`)\n",
    "- El optimizador y su estado, según corresponda (esto le permite reiniciar el entrenamiento donde lo dejó)\n",
    "\n",
    "Keras no puede guardar los optimizadores `v1.x` (desde `tf.compat.v1.train`) ya que no son compatibles con los puntos de verificación. Para los optimizadores v1.x, debe volver a compilar el modelo después de la carga; con lo que se pierde el estado del optimizador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAUKJQyGqTNH"
   },
   "source": [
    "### Guardar objetos personalizados\n",
    "\n",
    "Si está usando el formato SavedModel, puede omitir esta sección. La principal diferencia entre los formatos `.keras`/HDF5 de alto nivel y el formato SavedModel de bajo nivel es que los formatos `.keras`/HDF5 usan configuraciones de objetos para guardar la arquitectura del modelo, mientras que SavedModel guarda el gráfico de ejecución. Por lo tanto, los formatos SavedModel pueden guardar objetos personalizados como modelos subclasificados y capas personalizadas sin solicitar el código original. Sin embargo, como resultado, depurar SavedModels de bajo nivel puede ser una tarea más complicada, y recomendamos que use el formato `.keras` de alto nivel en su lugar, ya que está basado en nombres y es nativo de Keras.\n",
    "\n",
    "Para guardar objetos personalizados en `.keras` y HDF5, debe hacer lo siguiente:\n",
    "\n",
    "1. Defina un método `get_config` en su objeto y, si lo desea, un método de clase `from_config`.\n",
    "    - `get_config(self)` devuelve un diccionario serializable JSON de parámetros necesarios para recrear el objeto.\n",
    "    - `from_config(cls, config)` usa la configuración que devuelve `get_config` para crear un nuevo objeto. De forma predeterminada, esta función usará la configuración como kwargs de inicialización (`return cls(**config)`).\n",
    "2. Pase los objetos personalizados al modelo de una de las siguientes tres maneras:\n",
    "    - Registre el objeto personalizado con el decorador `@tf.keras.utils.register_keras_serializable`. **(opción recomendada)**\n",
    "    - Pase el objeto directamente al argumento `custom_objects` cuando cargue el modelo. El argumento debe ser un diccionario que asigne el nombre de clase de la cadena a la clase de Python. Por ejemplo, `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`\n",
    "    - Use `tf.keras.utils.custom_object_scope` con el objeto incluido en el argumento de diccionario `custom_objects` y coloque una llamada `tf.keras.models.load_model(path)` dentro del ámbito.\n",
    "\n",
    "Consulte el tutorial [Escribir capas y modelos desde cero](https://www.tensorflow.org/guide/keras/custom_layers_and_models) para ver ejemplos de objetos personalizados y `get_config`.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "basics.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
